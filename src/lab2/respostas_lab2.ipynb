{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. What is the cache capacity of the computer you used (please write the workstation name)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lab7p4 ([i5-3570](https://www.cpu-world.com/CPUs/Core_i5/Intel-Core%20i5-3570.html))\n",
    "\n",
    "`lscpu -C`\n",
    "\n",
    "L1d cache:                       128 KiB (4x 32 KiB)  \n",
    "L1i cache:                       128 KiB (4x 32 KiB)  \n",
    "L2 cache:                        1 MiB (4x 256 KiB)  \n",
    "L3 cache:                        6 MiB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import count\n",
    "from math import log2\n",
    "\n",
    "\n",
    "memo_num_accesses = {}\n",
    "\n",
    "\n",
    "def num_accesses(array_size):\n",
    "    \"\"\"Array size in KiB\"\"\"\n",
    "\n",
    "    key = array_size\n",
    "    if key in memo_num_accesses:\n",
    "        return memo_num_accesses[key]\n",
    "\n",
    "    array_size = array_size << 10\n",
    "\n",
    "    N_REPETITIONS = 100\n",
    "\n",
    "    STRIDE_MAX = 2\n",
    "\n",
    "    counter = 0\n",
    "    stride = 1\n",
    "\n",
    "    for stride in range(1, STRIDE_MAX, stride):\n",
    "\n",
    "        limit = array_size - stride + 1\n",
    "\n",
    "        # warm up\n",
    "        ## for i in range(0, limit, stride ):\n",
    "        ## counter+= 1\n",
    "\n",
    "        # main loop\n",
    "        for repeat in range(0, N_REPETITIONS * stride):\n",
    "            counter += (limit - 0) / stride\n",
    "\n",
    "    counter = int(counter)\n",
    "    memo_num_accesses[key] = counter\n",
    "\n",
    "    return counter\n",
    "\n",
    "\n",
    "for size in range(2, 13):\n",
    "    size_kb = 1 << size\n",
    "    print(f\"{size_kb: >4} KiB\\t{num_accesses(size_kb)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for i in range(8):\n",
    "    df = pd.concat((df, pd.read_csv(f\"./data/spark{i:0>2}.tsv\", delimiter=\"\\t\")))\n",
    "\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg = df.groupby([\"size\"], as_index=False).mean().drop(\"index\", axis=1)\n",
    "\n",
    "df_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg[\"accesses\"] = df_avg[\"size\"].apply(lambda x: num_accesses(x >> 10))\n",
    "df_avg[\"mean_access_time\"] = df_avg[\"elapsed(s)\"] / df_avg[\"accesses\"]\n",
    "df_avg[\"mean_access_time (ns)\"] = df_avg[\"mean_access_time\"].apply(\n",
    "    lambda x: x * 10**9\n",
    ")\n",
    "df_avg[\"size (KiB)\"] = df_avg[\"size\"].apply(lambda x: x >> 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg.sort_values(\"size\")[\n",
    "    [\"size (KiB)\", \"elapsed(s)\", \"accesses\", \"mean_access_time (ns)\"]\n",
    "].head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We used the computer lab7p4.  \n",
    "> From the table above, we can see that until size 32KiB (inclusive), the mean access time is practically constant.\n",
    "> When size is 64KiB, the mean access time slightly increases, leading us to believe the miss rate also increased,\n",
    "> which means we must've filled up the cache.  \n",
    "> Therefore, we reach the conclusion that the cache size is **32KiB**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. What is the cache capacity of the computer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> From Figure 1, we can observe two groups of array sizes distinguished by cache access time:\n",
    "> a group with a beginning ~360ns access time and the second group with ~500ns.\n",
    "> We can infer that the first group corresponds to array sizes with sizes lower or equal to the cache capacity,\n",
    "> since the second group has a higher execution time, which corresponds to the varying time miss penalties.\n",
    "> All of the arrays in the first group can be kept completely in cache, since they are of lower or equal size than the cache.\n",
    ">\n",
    "> Therefore, the cache capacity corresponds to the maximum array size on the group with lower time access: **64KiB**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. What is the size of each cache block?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The size of a cache block can be determined by observing the stride where the access\n",
    "> time, for the array size group with higher access times, stabilizes.\n",
    "> The access time stabilizes when the stride is equal or higher than the cache block size,\n",
    "> since each accessed element of the array will correspond to different blocks on the cache,\n",
    "> resulting in a 100% miss rate, and therefore an access time that will be the same for the subsequent strides.\n",
    ">\n",
    "> This is observed to happen on stride of **16 Bytes**, which means each cache block has a size of **16 Bytes**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. What is the L1 cache miss penalty time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Penalty time for a read + write: {1000 - 360}\")\n",
    "\n",
    "print(f\"Penalty time for one memory acess: (1000 - 360) / 2 = {(1000 - 360) / 2}\")\n",
    "# TODO check issue 36\n",
    "# 1000 - 360"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We can calculate the L1 cache miss penalty time by comparing the total execution\n",
    "> time when the miss rate is aproximately 0% with when it is aproximately 100%.\n",
    ">\n",
    "> The miss rate is aproximately 0% for array sizes smaller than the cache size,\n",
    "> that is, when the access time is around **360ms**.\n",
    "> It is aproximately 100% for the higher sized arrays along with a stride greater\n",
    "> than or equal to 16 bytes, that is, when the access time is around **1000ms**.\n",
    ">\n",
    "> Therefore, the miss penalty is **1000 - 360 = 640ms**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Modeling Computer Caches\n",
    "In the first part of this assignment, the goal is to model the characteristics of the L1 data cache and L2\n",
    "cache of the targeted computer platform. Next, we provide instructions for performing this analysis.\n",
    "Use the forms at the end to answer the questions below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Modeling the L1 Data Cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Change to directory cm1/, in the package lab2_kit.zip, and analyze de code of the program\n",
    "cm1.c. Identify its source code with the program described above.\n",
    "\n",
    "What are the processor events that will be analyzed during its execution? Explain their meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The event analized in the `cm1.c` program is `PAPI_L1_DCM`, which means, \"L1 Data Cache Misses\".  \n",
    "> This means that we will analize how many data cache misses, that is, how many times we tried to fetch data that was not in the L1 cache, during the execution of the program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Compile the program cm1.c using the provided Makefile and execute cm1. \n",
    "\n",
    "Plot the variation of\n",
    "the average number of misses (Avg Misses) with the stride size, for each considered dimension\n",
    "of the L1 data cache (8kB, 16kB, 32kB and 64kB).\n",
    "\n",
    "Note that, you may fill these tables and graphics (as well as the following ones in this report)\n",
    "on your computer and submit the printed version.\n",
    "\n",
    "NOTE: A fast sketch of these plots can be drawn in your computer by running the following commands:\n",
    "./cm1 > cm1.out\n",
    "./cm1_proc.sh\n",
    "\n",
    "NOTE 2: You can draw these tables and plots on your computer, print, and attach to the report. You do not have to fill them by hand on the printed report.\n",
    "\n",
    "NOTE 3: You may need to mark the script as executable before being able to run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_labels(val):\n",
    "    value = val.split(\"=\")[1]\n",
    "    return float(value) if \".\" in value else int(value)\n",
    "\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for i in range(10):\n",
    "    df = pd.concat(\n",
    "        (\n",
    "            df,\n",
    "            pd.read_csv(\n",
    "                f\"./data/cm1_data{i:0>2}.tsv\",\n",
    "                delimiter=\"\\t\",\n",
    "                names=[\"cache_size\", \"stride\", \"avg_misses\", \"avg_time\"],\n",
    "                converters={\n",
    "                    \"cache_size\": strip_labels,\n",
    "                    \"stride\": strip_labels,\n",
    "                    \"avg_misses\": strip_labels,\n",
    "                    \"avg_time\": strip_labels,\n",
    "                },\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg = (\n",
    "    df.groupby([\"cache_size\", \"stride\"], as_index=False).median().drop(\"index\", axis=1)\n",
    ")\n",
    "\n",
    "df_avg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import drawSvg as draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = draw.Drawing(300, 320)\n",
    "\n",
    "for y, i in zip(range(310, 40, -10), range(0, 27)):\n",
    "    d.append(\n",
    "        draw.Text(\n",
    "            f\"{df_avg['avg_misses'][i]:.6f}\", 8, 0, y, style=\"font-family: 'monospace'\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "for y, i in zip(range(310, 40, -10), range(0, 27)):\n",
    "    d.append(\n",
    "        draw.Text(\n",
    "            f\"{df_avg['avg_time'][i]:.6f}\",\n",
    "            8,\n",
    "            0 + 50,\n",
    "            y,\n",
    "            style=\"font-family: 'monospace'\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "for y, i in zip(range(310, 0, -10), range(27, 58)):\n",
    "    d.append(\n",
    "        draw.Text(\n",
    "            f\"{df_avg['avg_misses'][i]:.6f}\",\n",
    "            8,\n",
    "            183,\n",
    "            y,\n",
    "            style=\"font-family: 'monospace'\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "for y, i in zip(range(310, 0, -10), range(27, 58)):\n",
    "    d.append(\n",
    "        draw.Text(\n",
    "            f\"{df_avg['avg_time'][i]:.6f}\",\n",
    "            8,\n",
    "            183 + 50,\n",
    "            y,\n",
    "            style=\"font-family: 'monospace'\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "d.setPixelScale(1.76)\n",
    "\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams[\"figure.figsize\"] = [16, 12]\n",
    "sns.set_theme(context=\"poster\", style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_results = sns.lineplot(\n",
    "    data=df_avg, x=\"stride\", y=\"avg_misses\", hue=\"cache_size\", palette=\"deep\"\n",
    ")\n",
    "g_results.set_xscale(\"log\", base=2)\n",
    "g_results.set_xlabel(\"Strides (Bytes)\")\n",
    "g_results.set_ylabel(\"Average Misses\")\n",
    "g_results.get_legend().set_title(\"Cache Size (Bytes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) By analyzing the obtained results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Determine the **size** of the L1 data cache. Justify your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA\n",
    "l1_max_cache_size = 1 << 5  # in KiB, the last line that stays flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"L1 cache size = {l1_max_cache_size} KiB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We can determine the cache size by looking at the plot and finding the greatest\n",
    "> test cache size that always has \"average misses\" as zero.\n",
    "> In this case, the **green line (32KiB)** is the size that matches this description.\n",
    "> It has a small bump at stride 2^7, but it can be ignored due to the cache being occupied by other data from the program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Determine the **block size** adopted in this cache. Justify your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA\n",
    "l1_block_size = 1 << 6  # in bytes; when the line gets flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"L1 block size = {l1_block_size} B\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> When stride is less than **64 Bytes**, the miss rate keeps increasing, which means\n",
    "> that there are some accesses that keep hitting the cache, that is, they are inside\n",
    "> the same block as the previous access.  \n",
    "> Once the plot flattens, it means we've broken outside the bounds of the block,\n",
    "> that is, sequential accesses are on different blocks.\n",
    "> For this reason, we know that the block size is **64 Bytes**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Characterize the **associativity set size** adopted in this cache. Justify your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA\n",
    "l1_first_back_to_zero = 13  # first stride where cache miss of a certain array size (larger than cache size) goes back to zero\n",
    "l1_first_back_to_zero_array_size = 16  # log2 of the array size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_associativity_set_size = 1 << (\n",
    "    l1_first_back_to_zero_array_size - l1_first_back_to_zero\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"L1 associativity set size = 2^{l1_first_back_to_zero_array_size} / 2^{l1_first_back_to_zero} = {l1_associativity_set_size}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> To determine the associativity set size, we have to analyze in which stride size\n",
    "> the miss rate decreases back to zero for the largest cache (that is, red line **64KiB**).\n",
    "> Because the stride determines how many blocks of array data we're going to access, we\n",
    "> know that for a stride of 2^15 (the maximum for this array size) we're only going\n",
    "> to access 2 different blocks of this cache. If the cache is, at least, 2-way associative,\n",
    "> we're going to have a near-zero miss rate.  \n",
    "> If we repeat this process for lower strides, we notice that for 2^14 and 2^13 the\n",
    "> miss rate is also near-zero. This must mean the cache is, at least, 4-way or 8-way associative,\n",
    "> respectively.\n",
    "> For a lower stride of 2^12, this is no longer the case, so we must have surpassed\n",
    "> the number of ways of our cache.\n",
    ">\n",
    "> Therefore, the associativity set size must be 8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Modeling the L2 Cache\n",
    "In this part of the assignment, the goal is to experimentally model the characteristics of the L2 cache of the targeted computer platform. To analyze the computer’s L2 cache, we will use the same methodology that was introduced in the previous section to model the L1 data cache."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Modify the program cm1.c in order to analyze the characteristics of the L2 cache. (Hint: use the\n",
    "event PAPI_L2_DCM.)\n",
    "\n",
    "_Describe and justify the changes introduced in this program._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We've changed two things:\n",
    "> - the PAPI event, which we've changed from `PAPI_L1_DCM` to `PAPI_L2_DCM`,\n",
    ">   since we want to measure the miss rate of the L2 cache now.\n",
    "> - the `CACHE_MAX` value has been increased to 2MiB, since the L2 is much larger than the L1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Compile the program cm1.c, execute cm1, and plot the variation of the average number of misses\n",
    "(Avg Misses) with the stride size, for each considered dimension of the L2 cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_labels(val):\n",
    "    value = val.split(\"=\")[1]\n",
    "    return float(value) if \".\" in value else int(value)\n",
    "\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for i in range(10):\n",
    "    df = pd.concat(\n",
    "        (\n",
    "            df,\n",
    "            pd.read_csv(\n",
    "                f\"./data/cm1_l2_data{i:0>2}.tsv\",\n",
    "                delimiter=\"\\t\",\n",
    "                names=[\"cache_size\", \"stride\", \"avg_misses\", \"avg_time\"],\n",
    "                converters={\n",
    "                    \"cache_size\": strip_labels,\n",
    "                    \"stride\": strip_labels,\n",
    "                    \"avg_misses\": strip_labels,\n",
    "                    \"avg_time\": strip_labels,\n",
    "                },\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg = (\n",
    "    df.groupby([\"cache_size\", \"stride\"], as_index=False).median().drop(\"index\", axis=1)\n",
    ")\n",
    "\n",
    "df_avg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_results = sns.lineplot(\n",
    "    data=df_avg, x=\"stride\", y=\"avg_misses\", hue=\"cache_size\", palette=\"deep\"\n",
    ")\n",
    "g_results.set_xscale(\"log\", base=2)\n",
    "g_results.set_xlabel(\"Strides (Bytes)\")\n",
    "g_results.set_ylabel(\"Average Misses\")\n",
    "g_results.get_legend().set_title(\"Cache Size (Bytes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) By analyzing the obtained results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Determine the size of the L2 cache. Justify your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA\n",
    "l2_max_cache_size = 1 << 8  # in KiB, the last line that doesn't have a miss rate of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"L2 cache size = {l2_max_cache_size} KiB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We can determine the cache size by looking at the plot and finding the greatest\n",
    "> test cache size that doesn't have a miss rate of 1 when it stabilizes.\n",
    "> \n",
    "> In this case, the **brown line (256KiB)** is the size that matches this description."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Determine the block size adopted in this cache. Justify your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA\n",
    "l2_block_size = 1 << 6  # in bytes; when the line gets flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"L2 block size = {l1_block_size} B\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> When stride is less than **64 Bytes**, the miss rate keeps increasing, which means\n",
    "> that there are some accesses that keep hitting the cache, that is, they are inside\n",
    "> the same block as the previous access.  \n",
    "> Once the plot flattens, it means we've broken outside the bounds of the block,\n",
    "> that is, sequential accesses are on different blocks.\n",
    "> For this reason, we know that the block size is **64 Bytes**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Characterize the associativity set size adopted in this cache. Justify your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA\n",
    "l2_first_back_to_zero = 16  # first stride where cache miss of a certain array size (larger than cache size) goes back to zero\n",
    "l2_first_back_to_zero_array_size = 21  # log2 of the array size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_associativity_set_size = 1 << (\n",
    "    l2_first_back_to_zero_array_size - l2_first_back_to_zero\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"L2 associativity set size = 2^{l2_first_back_to_zero_array_size} / 2^{l2_first_back_to_zero} = {l2_associativity_set_size}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Like on L1, we can find out the associativity set size by finding the first stride when the miss rate goes back to zero for a certain array size\n",
    "> (refer to the answer to L1 for full explanation).  \n",
    "> Dividing the array size by the size of that stride will result in the associativity set size.  \n",
    "> This is a more methodic way of calculating this value compared to what we've done on L1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Profiling and Optimizing Data Cache Accesses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Straightforward implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Change to directory mm1/ and analyze de code of the program mm1.c. Identify its source code\n",
    "with the program described above.\n",
    "\n",
    "What is the total amount of memory that is required to accommodate each of these matrices?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA\n",
    "size_of_int16 = 2  # int16_t takes up 2 bytes\n",
    "array_n = 512  # defined as a constant in mm1.c\n",
    "\n",
    "matrix_size_in_bytes = size_of_int16 * array_n * array_n\n",
    "\n",
    "print(\n",
    "    f\"Each matrix takes up {matrix_size_in_bytes} Bytes ({matrix_size_in_bytes >> 10} KiB)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Compile the source file mm1.c using the provided Makefile and execute it. \n",
    "\n",
    "Fill the table with the obtained data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA (raw)\n",
    "straightforward_l1_miss_count = 134.618787  # PAPI_L1_DCM\n",
    "straightforward_load_instructions = 3491.029128  # PAPI_LD_INS\n",
    "straightforward_store_instructions = 672.141375  # PAPI_SR_INS\n",
    "straightforward_wall_clock_cycles = 3998.652442\n",
    "straightforward_elapsed_time = 1.178761\n",
    "\n",
    "straightforward_mem_instructions = (\n",
    "    straightforward_load_instructions + straightforward_store_instructions\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Total number of L1 data cache misses:\\t\\t\\t{straightforward_l1_miss_count} x 10^6\"\n",
    ")\n",
    "print(\n",
    "    f\"Total number of load / store instructions completed:\\t{straightforward_mem_instructions} x 10^6\"\n",
    ")\n",
    "print(\n",
    "    f\"Total number of clock cycles:\\t\\t\\t\\t{straightforward_wall_clock_cycles} x 10^6\"\n",
    ")\n",
    "print(f\"Elapsed time:\\t\\t\\t\\t\\t\\t{straightforward_elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Evaluate the resulting L1 data cache Hit-Rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "straightforward_hit_rate = 1 - (\n",
    "    straightforward_l1_miss_count / straightforward_mem_instructions\n",
    ")\n",
    "\n",
    "print(f\"Data Hit Rate: {straightforward_hit_rate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 96.77% de data cache hit, as matrizes não cabem todas na L1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 First Optimization: Matrix transpose before multiplication [2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Change to directory mm2/ and analyze the code of the program mm2.c. Identify its source code\n",
    "with the program described above. Compile this program using the provided Makefile and execute it.\n",
    "\n",
    "Fill the table with the obtained data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA (raw)\n",
    "transpose_l1_miss_count = 4.211422  # PAPI_L1_DCM\n",
    "transpose_load_instructions = 402.665233  # PAPI_LD_INS\n",
    "transpose_store_instructions = 134.217780  # PAPI_SR_INS\n",
    "transpose_wall_clock_cycles = 732.935875\n",
    "transpose_elapsed_time = 0.216062\n",
    "\n",
    "transpose_mem_instructions = transpose_load_instructions + transpose_store_instructions\n",
    "\n",
    "print(f\"Total number of L1 data cache misses:\\t\\t\\t{transpose_l1_miss_count} x 10^6\")\n",
    "print(\n",
    "    f\"Total number of load / store instructions completed:\\t{transpose_mem_instructions} x 10^6\"\n",
    ")\n",
    "print(f\"Total number of clock cycles:\\t\\t\\t\\t{transpose_wall_clock_cycles} x 10^6\")\n",
    "print(f\"Elapsed time:\\t\\t\\t\\t\\t\\t{transpose_elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Evaluate the resulting L1 data cache Hit-Rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transpose_hit_rate = 1 - (transpose_l1_miss_count / transpose_mem_instructions)\n",
    "\n",
    "print(f\"Data Hit Rate: {transpose_hit_rate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Change the code in the program mm2.c in order to include the matrix transposition in the execution\n",
    "time. Compile this program using the provided Makefile and execute it.\n",
    "\n",
    "Fill the table with the obtained data.\n",
    "\n",
    "Comment on the obtained results when including the matrix transposition in the execution time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA (raw)\n",
    "transpose2_l1_miss_count = 4.481951  # PAPI_L1_DCM\n",
    "transpose2_load_instructions = 402.928468  # PAPI_LD_INS\n",
    "transpose2_store_instructions = 134.479925  # PAPI_SR_INS\n",
    "transpose2_wall_clock_cycles = 735.191102\n",
    "transpose2_elapsed_time = 0.216727\n",
    "\n",
    "transpose2_mem_instructions = (\n",
    "    transpose2_load_instructions + transpose2_store_instructions\n",
    ")\n",
    "\n",
    "print(f\"Total number of L1 data cache misses:\\t\\t\\t{transpose2_l1_miss_count} x 10^6\")\n",
    "print(\n",
    "    f\"Total number of load / store instructions completed:\\t{transpose2_mem_instructions} x 10^6\"\n",
    ")\n",
    "print(f\"Total number of clock cycles:\\t\\t\\t\\t{transpose2_wall_clock_cycles} x 10^6\")\n",
    "print(f\"Elapsed time:\\t\\t\\t\\t\\t\\t{transpose2_elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transpose2_hit_rate = 1 - (transpose2_l1_miss_count / transpose2_mem_instructions)\n",
    "\n",
    "print(f\"Data Hit Rate: {transpose2_hit_rate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> By comparing both results, we reach the conclusion that including the matrix transposition\n",
    "> in the execution time does not significantly alter the obtained results.\n",
    "> This most likely happens because matrix transposition ($O(N^2)$) is a much faster and less\n",
    "> computationally intensive process than matrix multiplication ($O(N^3)$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Compare the obtained results with those that were obtained for the straightforward implementation,\n",
    "by calculating the difference of the resulting hit-rates (∆HitRate) and the obtained speedups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Delta Hit Rate = HitRate mm2 - HitRate mm1: \\t{transpose2_hit_rate - straightforward_hit_rate}\"\n",
    ")\n",
    "print(\n",
    "    f\"Speedup(#Clocks) = #Clocks mm1 / #Clocks mm2 \\t{straightforward_wall_clock_cycles / transpose2_wall_clock_cycles}\"\n",
    ")\n",
    "print(\n",
    "    f\"Speedup(Time) = Time mm1 / Time mm2 \\t{straightforward_elapsed_time / transpose2_elapsed_time}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> As expected, the cost of doing extra memory accesses was easily recovered by now iterating over the matrices sequentially , resulting in a significant Speedup of around 5.4 - despite the fact that the hit rate didn't receive much of an improvement. We can conclude that taking advantage of the principle of locality should, in general, result in better performance. This optimization may not be desirable, however, if memory size restrictions are a concern, since a new NxN matrix has to be stored in memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 Second Optimization: Blocked (tiled) matrix multiply [2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Change to directory mm3/ and analyze the code of the program mm3.c. Identify its source code\n",
    "with the program described above.\n",
    "\n",
    "Change the program source code in order to comply the algorithm parameterization (sub-matrix\n",
    "line size) with the block size (CLS) that was determined in Section 3.1.\n",
    "\n",
    "How many matrix elements can be accommodated in each cache line?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_line_size = 64  # KiB\n",
    "m_element_size = 2  # = size_of_int16 = 2  # int16_t takes up 2 bytes\n",
    "elements_per_cache_line = 64 / 2\n",
    "print(f\"In each cache line there can be {elements_per_cache_line} matrix elements\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Compile this program using the provided Makefile and execute it. \n",
    "\n",
    "Fill the table with the obtained data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA (raw)\n",
    "blocked_l1_miss_count = 5.508321  # PAPI_L1_DCM\n",
    "blocked_load_instructions = 402.802480  # PAPI_LD_INS\n",
    "blocked_store_instructions = 134.222203  # PAPI_SR_INS\n",
    "blocked_wall_clock_cycles = 394.415740\n",
    "blocked_elapsed_time = 0.116269\n",
    "\n",
    "blocked_mem_instructions = blocked_load_instructions + blocked_store_instructions\n",
    "\n",
    "print(f\"Total number of L1 data cache misses:\\t\\t\\t{blocked_l1_miss_count} x 10^6\")\n",
    "print(\n",
    "    f\"Total number of load / store instructions completed:\\t{blocked_mem_instructions} x 10^6\"\n",
    ")\n",
    "print(f\"Total number of clock cycles:\\t\\t\\t\\t{blocked_wall_clock_cycles} x 10^6\")\n",
    "print(f\"Elapsed time:\\t\\t\\t\\t\\t\\t{blocked_elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Evaluate the resulting L1 data cache Hit-Rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocked_hit_rate = 1 - (blocked_l1_miss_count / blocked_mem_instructions)\n",
    "\n",
    "print(f\"Data Hit Rate: {blocked_hit_rate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "98.97%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Compare the obtained results with those that were obtained for the straightforward implementation,\n",
    "by calculating the difference of the resulting hit-rates (∆HitRate) and the obtained speedup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Delta Hit Rate = HitRate mm3 - HitRate mm1: \\t{blocked_hit_rate - straightforward_hit_rate}\"\n",
    ")\n",
    "print(\n",
    "    f\"Speedup(#Clocks) = #Clocks mm1 / #Clocks mm3 \\t{straightforward_wall_clock_cycles / blocked_wall_clock_cycles}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> A near 10.0 Speedup (without any significant hit rate changes) was achieved by merely processing the matrix in several sub-matrixes - simply ensuring respect for the  principle of locality. The only relevant trade-off is that the source code is now moderately less straightforward to read than the original version's."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Compare the obtained results with those that were obtained for the matrix transpose implementation by calculating the difference of the resulting hit-rates (∆HitRate) and the obtained speedup.\n",
    "\n",
    "If the obtained speedup is positive, but the difference of the resulting hit-rates is negative, how\n",
    "do you explain the performance improvement? \n",
    "\n",
    "(Hint: study the hit-rates of the L2 cache for both\n",
    "implementations; You may use the following PAPI events PAPI_L2_DCH (or PAPI_L2_DCM)\n",
    "and PAPI_L2_DCA. Run papi_avail to check for available events and understand their meaning.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Delta Hit Rate = HitRate mm3 - HitRate mm2: \\t{blocked_hit_rate - transpose2_hit_rate}\"\n",
    ")\n",
    "print(\n",
    "    f\"Speedup(#Clocks) = #Clocks mm2 / #Clocks mm3 \\t{transpose2_wall_clock_cycles / blocked_wall_clock_cycles}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> // TODO"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
